{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85f76274",
   "metadata": {},
   "source": [
    "#### Getting started With Langchain And Open AI\n",
    "\n",
    "In this quickstart we'll see how to:\n",
    "\n",
    "- Get setup with LangChain, LangSmith and LangServe\n",
    "- Use the most basic and common components of LangChain: prompt templates, models, and output parsers.\n",
    "- Build a simple application with LangChain\n",
    "- Trace your application with LangSmith\n",
    "- Serve your application with LangServe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ee5ade8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "445158da",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['OPENAI_API_KEY'] = os.getenv(\"OPENAI_API_KEY_1\")\n",
    "## Langsmith Tracking\n",
    "os.environ[\"LANGCHAIN_API_KEY\"]=os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"]=\"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"]=os.getenv(\"LANGCHAIN_PROJECT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "901e6f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Mtech AI KU\\deeplearningproject\\Langgraph\\langbho\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "profile={'max_input_tokens': 128000, 'max_output_tokens': 16384, 'image_inputs': True, 'audio_inputs': False, 'video_inputs': False, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': False, 'tool_calling': True, 'structured_output': True, 'image_url_inputs': True, 'pdf_inputs': True, 'pdf_tool_message': True, 'image_tool_message': True, 'tool_choice': True} client=<openai.resources.chat.completions.completions.Completions object at 0x000001E22570DD20> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000001E25279D360> root_client=<openai.OpenAI object at 0x000001E2521A32B0> root_async_client=<openai.AsyncOpenAI object at 0x000001E25279D2D0> model_name='gpt-4o' model_kwargs={} openai_api_key=SecretStr('**********') stream_usage=True\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm=ChatOpenAI(model=\"gpt-4o\")\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdbcd882",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Input and get response form LLM\n",
    "\n",
    "result=llm.invoke(\"What is generative AI?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95923729",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Generative AI refers to a category of artificial intelligence systems designed to produce new content by learning patterns and structures from existing data. Unlike traditional AI, which focuses on analyzing data and providing insights, generative AI creates something novelâ€”be it text, images, music, code, or other types of content. The technology often involves machine learning models called generative models, such as Generative Adversarial Networks (GANs), Variational Autoencoders (VAEs), and Transformer models like GPT (Generative Pre-trained Transformer).\\n\\nKey applications of generative AI include:\\n\\n1. **Text Generation**: Models like GPT can generate human-like written text, perform language translation, and even engage in conversational interactions.\\n2. **Image Creation**: GANs can generate high-quality images, ranging from artistic styles to realistic portraits.\\n3. **Music Composition**: AI can compose music by learning from existing musical compositions.\\n4. **Design and Art**: Generative AI can produce new designs and artworks, often used by artists and designers as a tool to enhance creativity.\\n5. **Code Generation**: AI can assist in writing code by predicting snippets or even generating entire functions based on a given context or task description.\\n\\nGenerative AI has a wide array of uses across different industries, powering applications from creative content development to more practical applications like drug discovery, where it generates new molecular structures. Despite its potential, it also raises ethical concerns such as the propagation of misinformation, the creation of deepfakes, and issues related to intellectual property and authorship.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 311, 'prompt_tokens': 13, 'total_tokens': 324, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_deacdd5f6f', 'id': 'chatcmpl-D1oWvd57dexd69iAs5e8nhZazz3Xq', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019bf3fb-c63f-7213-8873-215a49751dfa-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 13, 'output_tokens': 311, 'total_tokens': 324, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f37ebc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an expert AI Engineer. Provide me answers based on the questions'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Chatprompt Template\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are an expert AI Engineer. Provide me answers based on the questions\"),\n",
    "        (\"user\",\"{input}\")\n",
    "    ]\n",
    "\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2f4a89d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Langsmith is a comprehensive platform developed by Langchain designed to streamline and enhance the development of applications powered by large language models (LLMs) and chat models. It addresses the complexities of tracing, debugging, testing, evaluating, and monitoring these models. Langsmith offers integrated capabilities that allow developers to fine-tune prompts, track performance, and conduct A/B testing through reliable real-time analytics. As an integral tool within the Langchain ecosystem, it helps in tracking application outcomes and refining model interactions to ensure robust, efficient, and effective natural language processing applications.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 111, 'prompt_tokens': 33, 'total_tokens': 144, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_deacdd5f6f', 'id': 'chatcmpl-D1odmFHpw4Pf56NOeO3Zc3MeTtg0b', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--019bf402-404e-7c73-b5bf-f5bd9df73d81-0' tool_calls=[] invalid_tool_calls=[] usage_metadata={'input_tokens': 33, 'output_tokens': 111, 'total_tokens': 144, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "## chain \n",
    "chain=prompt|llm\n",
    "\n",
    "response=chain.invoke({\"input\":\"Can you tell me about Langsmith?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "748cf461",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d99614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Langsmith is a toolset for building advanced language model applications and is provided by LangChain. It facilitates application development by enabling language models to be tested, debugged, monitored, and evaluated, either manually or through automated processes. Key features of Langsmith include the ability to log requests made to language model applications, visualize how these requests move through the application, and monitor model performance over time. These capabilities help developers identify and resolve issues pertaining to token usage, LLM latencies, model costs, and other relevant metrics, thereby optimizing the functionality and efficiency of the application.\n"
     ]
    }
   ],
   "source": [
    "## stroutput Parser\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "output_parser=StrOutputParser()\n",
    "chain=prompt|llm|output_parser\n",
    "\n",
    "response=chain.invoke({\"input\":\"Can you tell me about Langsmith?\"})\n",
    "print(response)\n",
    "\n",
    "## In summary This code builds an end-to-end LangChain pipeline that takes user input, formats it as a chat prompt, sends it to an LLM, converts the response into plain text, and returns it."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
